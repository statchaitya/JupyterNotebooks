{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow in Practice Course 1: Week 2\n",
    "\n",
    "1. Vid1: A conversation with andrew ng\n",
    "2. Vid2: An introduction to computer vision\n",
    "    - Basic intro\n",
    "    - Intro to fashion MNIST dataset\n",
    "    - Intuition about what a computer vision model does\n",
    "3. Reading: Exploring how to use data\n",
    "4. [Vid3: Writing code to load training data](#optparam1)\n",
    "5. [Reading: The structure of fashion MNIST data and avoiding bias](#optparam2)\n",
    "    - Bias reading at: https://developers.google.com/machine-learning/fairness-overview/\n",
    "6. [Vid4: Coding a computer vision neural network](#optparam3)\n",
    "7. Reading: See how its' done\n",
    "8. [Vid5: Walk through a notebook](#optparam4)\n",
    "9. Reading: Get hands on\n",
    "    - This reading is important\n",
    "    - They have given a few exercises which they've asked to try out\n",
    "    - Exercises could be found at the bottom [here](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%204%20-%20Lesson%202%20-%20Notebook.ipynb)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optparam1\"></a>\n",
    "### Loading data\n",
    "\n",
    "* fashion_mnist is a module\n",
    "* load_data() method on it downloads the data for us and saves it in a local directory\n",
    "* It also makes it availabe for us in a train-test split format.\n",
    "* We receive it as two tuples of train and test respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optparam2\"></a>\n",
    "### Structure of MNIST data\n",
    "\n",
    "* Lets quickly check the types of data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So the data is in the form of arrays i.e. pixel values\n",
    "* train_images has 60k images each of 28 x 28 size grey scale\n",
    "* labels are also 60k obviously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 10k images in the test dataset\n",
    "* First image in train set can be accessed using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using matplotlib we can plot an numpy array as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x277631f4940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data\n",
    "\n",
    "* Neural networks work well with normalized data\n",
    "* We will simply divide the image pixels by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see the value of pixels have changed in the previous printing of the same array\n",
    "\n",
    "<a id=\"optparam3\"></a>\n",
    "### Defining the model\n",
    "\n",
    "* keras.sequential defines what kind of a network its going to be ex: sequential, recurrent etc..\n",
    "* Within that we define a list. Each element of list comprises a layer in our network\n",
    "* We can use keras.layers module to pick and choose different layers\n",
    "* Since we have images as 28 x 28 matrices, we will need to flatten them as the first layer to our NN is always all pixels of the image as one array. That is exactly what keras.layer.Flatten() does\n",
    "* Next we add two dense layers. 128 is the number of hidden neurons\n",
    "* 10 is the number of labels\n",
    "* Last layer receives a softmax activation expectedly\n",
    "* Hidden layer receives a ReLu (rectified linear unit) activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optparam4\"></a>\n",
    "### Compiling, fitting and evaluating the model\n",
    "\n",
    "* Once a network is built in keras, a compile method is available to define **optimizer** and **loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5025\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3776\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3379\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3131\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2776044f080>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34690427780151367"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting hands on: Exercises\n",
    "\n",
    "* Where to find exercises is in the first cell of this notebook.\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "* *For this first exercise run the below code: It creates a set of classifications for each of the test images, and then prints the first entry in the classifications. The output, after you run it is a list of numbers. Why do you think this is, and what do those numbers represent?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2625068e-04 5.9904814e-08 2.7041457e-05 9.7035766e-08 9.8797909e-06\n",
      " 5.5887173e-03 1.0052215e-05 3.6535464e-02 5.0224178e-05 9.5765221e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Type and size of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So the output from model.predict() method is a matrix of size **num_test_examples x num_labels**\n",
    "* This means each row vector represents probabilities of that test example being the corresponding number\n",
    "* Ex: Following are the probabilities of test example 0 being each of the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.006, 0.0, 0.037, 0.0, 0.958]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_0 = list(classifications[0])\n",
    "pred_test_0 = [np.round(i, 3) for i in pred_test_0]\n",
    "pred_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So as we can see our model has predicted this to be the right label as the last element in **pred_test_0** representing the probabilitiy of the test_label[0] being 9 is the highest i.e. 93.9%\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "* *Let's now look at the layers in your model. Experiment with different values for the dense layer with 512 neurons. What different results do you get for loss, training time etc? Why do you think that's the case?*\n",
    "\n",
    "- **tf.keras.layers.Flatten()** unrolls the incoming input from the last layer into 1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4698\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3602\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3226\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2951\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2772\n",
      "\n",
      "\n",
      "The above operation took 1.2265979886054992 minutes to run\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy')\n",
    "start = time.time()\n",
    "model_2.fit(train_images, train_labels, epochs=5)\n",
    "end = time.time()\n",
    "print(\"\\n\")\n",
    "print(f\"The above operation took {(end - start)/60} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33423087000846863"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0, 0.999]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_2 = model_2.predict(test_images)\n",
    "pred_test_0 = list(classifications_2[0])\n",
    "pred_test_0 = [np.round(i, 3) for i in pred_test_0]\n",
    "pred_test_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We got a 0.33 loss on test which is not a very big improvement\n",
    "* So **increasing hidden neurons doesn't make an difference for our data**\n",
    "* We changed the hidden neurons to **1024**\n",
    "* Now lets try adding 2 hidden layers with less hidden neurons and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8077\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5212\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4755\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4290\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4111\n",
      "The above operation took 0.05931601126988729 minutes to run\n"
     ]
    }
   ],
   "source": [
    "model_3 = keras.models.Sequential([keras.layers.Flatten(),\n",
    "                                  keras.layers.Dense(56, activation=tf.nn.relu),\n",
    "                                  keras.layers.Dense(56, activation=tf.nn.relu),\n",
    "                                  keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model_3.compile(optimizer=tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy')\n",
    "start = time.time()\n",
    "model_3.fit(test_images, test_labels, epochs=5)\n",
    "end = time.time()\n",
    "print(f\"The above operation took {(end - start)/60} minutes to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see this model ran very quickly than eariler model only within a few seconds than 1+ minute.\n",
    "* Lets check the results now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3831\n",
      "Loss on test set for model_3 is 0.3830711543560028\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss on test set for model_3 is {model_3.evaluate(test_images, test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The loss worsened so adding additional layers also was not a great idea. Although I have given 56 neurons to each layer in this as opposed to 128 hidden units single hidden layer earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities model_3 predicted for 1st test example are [0.0, 0.0, 0.001, 0.0, 0.0, 0.131, 0.0, 0.475, 0.064, 0.328]\n"
     ]
    }
   ],
   "source": [
    "classifications_3 = model_3.predict(test_images)\n",
    "pred_test_0 = list(classifications_3[0])\n",
    "pred_test_0 = [np.round(i, 3) for i in pred_test_0]\n",
    "print(f\"\\nProbabilities model_3 predicted for 1st test example are {pred_test_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that the increased loss reflects in the proababilities as well i.e. proability values get worst.\n",
    "* Instead of 90+% probability for test example 0, we are now predicting this image to be label 9 with 32.8% probabilitiy\n",
    "\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "* *What would happen if you remove the Flatten() layer. Why do you think that's the case?*\n",
    "\n",
    "\n",
    "\n",
    "**Ans:** This is pretty straightforward as it will throw an error. Any image input to a network has to go in flattened for a multilayer perceptron atleast\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "* *Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5*\n",
    "\n",
    "**Ans:** Again for someone who has learnt how the architectures work, this is straightforward. Since, for training the data, we are providing exaclty 10 labels, our architecture needs to have an output of size 10.\n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "* *Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10.*\n",
    "\n",
    "**Ans:** We already did this above as an extra step in exercise 2. There was no big impact as this data is less complex so we don't need multiple layers to identify the patterns. If it was an **animal classifier** or something like that then we would need multiple layers.\n",
    "\n",
    "### Exercise 6\n",
    "\n",
    "* *Consider the impact of training for more or less epochs. Why do you think that would be the case?*\n",
    "\n",
    "* Lets try increasing epochs to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7161\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5167\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4636\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4333\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4025\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3780\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3573\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3461\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3220\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3115\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3006\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2876\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2771\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2617\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2548\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2427\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2457\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2276\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2230\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2159\n",
      "The above operation took 0.23200056155522664 minutes to run\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\\\n",
    "             loss='sparse_categorical_crossentropy')\n",
    "\n",
    "num_epochs = 20\n",
    "start = time.time()\n",
    "model.fit(test_images, test_labels, epochs=num_epochs)\n",
    "end = time.time()\n",
    "print(f\"The above operation took {(end - start)/60} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1960\n",
      "Loss on test set for model with 20 epochs is 0.1960430145263672\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss on test set for model with 20 epochs is {model.evaluate(test_images, test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increasing the epochs reduced the loss which is encouraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities model with 20 epochs predicted for 1st test example are [0.0, 0.0, 0.0, 0.0, 0.0, 0.011, 0.0, 0.518, 0.0, 0.47]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "pred_test_0 = list(classifications[0])\n",
    "pred_test_0 = [np.round(i, 3) for i in pred_test_0]\n",
    "print(f\"\\nProbabilities model with 20 epochs predicted for 1st test example are {pred_test_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But wait, why did the probabilities get worst then? This is due to **overfitting**. We trained the model so much that it adapted itself to the data it could see more than it should. And now when we give it unseen data, it is getting confused.\n",
    "* Lets try a bizzare number 50 now for epochs. We will pass **verbose=0** to fit method so that results are not printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above operation took 0.34328678448994954 minutes to run\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\\\n",
    "             loss='sparse_categorical_crossentropy')\n",
    "\n",
    "num_epochs = 50\n",
    "start = time.time()\n",
    "model.fit(test_images, test_labels, epochs=num_epochs, verbose=0)\n",
    "end = time.time()\n",
    "print(f\"The above operation took {(end - start)/60} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0625\n",
      "Loss on test set for model with 50 epochs is 0.06252358108758926\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss on test set for model with {num_epochs} epochs is {model.evaluate(test_images, test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The loss reduced further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities model with 50 epochs predicted for 1st test example are [0.0, 0.0, 0.0, 0.0, 0.0, 0.022, 0.0, 0.008, 0.0, 0.969]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "pred_test_0 = list(classifications[0])\n",
    "pred_test_0 = [np.round(i, 3) for i in pred_test_0]\n",
    "print(f\"\\nProbabilities model with {num_epochs} epochs predicted for 1st test example are {pred_test_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are getting good results on this training example\n",
    "* Although increasing the epochs so much is not ideally advisable but it will be interesting to figure out why the results got better. Would the results have stayed the same had we had one more validation set apart from test set?\n",
    "\n",
    "\n",
    "### Exercise 7\n",
    "\n",
    "* *Before you trained, you normalized the data, going from values that were 0-255 to values that were 0-1. What would be the impact of removing that? Here's the complete code to give it a try. Why do you think you get different results?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.6504\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6509\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5596\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5302\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216507c3b00>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy')\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 939us/step - loss: 0.0000e+00\n",
      "Loss on test set with model training on non-normalized data is 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss on test set with model training on non-normalized data is {model.evaluate(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Callbacks - to be done after the next video\n",
    "\n",
    "\n",
    "### Video 6: Callbacks\n",
    "\n",
    "* Lets say you want to train a model with 100 epochs but you don't want your performance to weaken.\n",
    "* You want to stop as soon as the performance starts getting worst.\n",
    "* Enter the world of callbacks. What callback does, is after every epoch, the validation metrics are diverted to a function which then checks the metrics.\n",
    "* If looking at the values, it is good to proceed, the model training proceeds else it terminates\n",
    "\n",
    "##### What is the following code potentially doing?\n",
    "\n",
    "* In the following code we create our own callback class which inherits from tf.keras.callbacks.Callback class\n",
    "* We pass the instance of the callback class to the model.fit() method\n",
    "* This object has all the details of the training process available and hence, the logs{} dict we provide to the on_epoch_end method is actually filled when it is called by the model.fit() object while training.\n",
    "* So when we provide an instance to the fit method, we will assume that the info will be available and we need to code the methods in the callback under this assumption. We just need to know the important details of **how** and **where** these details will be available ex: in logs dict.\n",
    "* In the call back class we define a method called as **on_epoch_end** which is called everytime the callback is executed.\n",
    "* In the function, we get a logs dict which has a lot of useful info about the training including what loss value is at the current iteration.\n",
    "* We can then use this loss info to modify the behaviour of the training further by changing an attribute of our class as we have set model.stop_training to True when loss goes below 0.4 in the following code.\n",
    "\n",
    "##### To use callbacks\n",
    "\n",
    "* We\n",
    "    1. define the callback class\n",
    "    2. instantiate it\n",
    "    3. let the fit method know that we want to use a callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5010\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3738\n",
      "Loss is low so cancelling training\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2777e059cf8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if (logs.get('loss') < 0.4):\n",
    "            print(\"\\nLoss is low so cancelling training\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks additional notes\n",
    "\n",
    "* model.fit() is like a paper plane. Apart from the inital impulse, you have no control over where the plane is going to end and if it is going to result in a wasted paper plane.\n",
    "* Drone is better as drone send the data back to its user, and acts on its current environment dynamically.\n",
    "* **Callbacks** convert the model.fit() from a paper plane to a drone which you have more control over.\n",
    "* CB has access to all the data being produced about the state of the model and its performance.\n",
    "\n",
    "### Following are a few things one can do using callbacks:\n",
    "\n",
    "* Model checkpointing—Saving the current weights of the model at different points during training.\n",
    "* Early stopping—Interrupting training when the validation loss is no longer improving (and of course, saving the best model obtained during training).\n",
    "* Dynamically adjusting the value of certain parameters during training—Such as the learning rate of the optimizer.\n",
    "* Logging training and validation metrics during training, or visualizing the representations learned by the model as they’re updated—The Keras progress bar that you’re familiar with is a callback!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
